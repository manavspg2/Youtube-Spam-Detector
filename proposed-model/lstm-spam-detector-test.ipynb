{"cells":[{"metadata":{"trusted":true,"_uuid":"1e369fe06f181c6e6222fbe758d8d2662345ff0a"},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import LabelEncoder\nfrom keras.models import Model\nfrom keras.layers import LSTM, Activation, Dense, Dropout, Input, Embedding\nfrom keras.optimizers import RMSprop\nfrom keras.preprocessing.text import Tokenizer\nfrom keras.preprocessing import sequence\nfrom keras.utils import to_categorical\nfrom keras.callbacks import EarlyStopping\n%matplotlib inline\n\n\ndf = pd.read_csv('../input/spam.csv',delimiter=',',encoding='latin-1')\ndf.head()\n\ndf.drop(['Unnamed: 2', 'Unnamed: 3', 'Unnamed: 4'],axis=1,inplace=True)\ndf.info()\n\nsns.countplot(df.v1)\nplt.xlabel('Label')\nplt.title('Number of ham and spam messages')\n\n\nX = df.v2\nY = df.v1\nle = LabelEncoder()\nY = le.fit_transform(Y)\nY = Y.reshape(-1,1)\n\nX_train,X_test,Y_train,Y_test = train_test_split(X,Y,test_size=0.15)\n\nprint(\"Xtrain shape == \", X_train.shape)\nmax_words = 1000\nmax_len = 150\ntok = Tokenizer(num_words=max_words)\nseq = tok.fit_on_texts(X_train)\n#below function turn words in text to sequence numbers \nsequences = tok.texts_to_sequences(X_train)\nprint(\"sequences\",sequences)\nprint(\"Length of sequence == \",len(sequences))\n\n#This function transforms a list of num_samples sequences (lists of integers) into a 2D\n#Numpy array of shape (num_samples, num_timesteps). num_timesteps\n#is either the maxlen argument if provided, or the length of the longest sequence otherwise\nsequences_matrix = sequence.pad_sequences(sequences,maxlen=max_len)\nprint(\"shape of sequence matrix == \",sequences_matrix.shape)\n\n\ndef RNN():\n    inputs = Input(name='inputs',shape=[max_len])\n    layer = Embedding(max_words,50,input_length=max_len)(inputs)\n    layer = LSTM(64)(layer)\n    layer = Dense(256,name='FC1')(layer)\n    layer = Activation('relu')(layer)\n    layer = Dropout(0.5)(layer)\n    layer = Dense(1,name='out_layer')(layer)\n    layer = Activation('sigmoid')(layer)\n    model = Model(inputs=inputs,outputs=layer)\n    return model\n\n\nmodel = RNN()\nmodel.summary()\nmodel.compile(loss='binary_crossentropy',optimizer=RMSprop(),metrics=['accuracy'])\n\nmodel.fit(sequences_matrix,Y_train,batch_size=128,epochs=10,\n          validation_split=0.2,callbacks=[EarlyStopping(monitor='val_loss',min_delta=0.0001)])\n\ntest_sequences = tok.texts_to_sequences(X_test)\ntest_sequences_matrix = sequence.pad_sequences(test_sequences,maxlen=max_len)\ntest_pred = model.predict(test_sequences_matrix)\ntest_pred = np.round(test_pred,0)\nprint(\"predicted spam as 1, ham as 0\",test_pred)\n\naccr = model.evaluate(test_sequences_matrix,Y_test)\n\nprint('Test set\\n  Loss: {:0.3f}\\n  Accuracy: {:0.3f}'.format(accr[0],accr[1]))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}